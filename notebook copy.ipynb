{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_So5uPjPWR61Gy3wOf2x853ZD', created_at=1717907719, description=None, instructions='You help users with their question on the files they upload', metadata={}, model='gpt-4o', name='Book Assistant', object='assistant', tools=[FileSearchTool(type='file_search', file_search=None)], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=[])), top_p=1.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Book Assistant\",\n",
    "  instructions=\"You help users with their question on the files they upload\",\n",
    "  tools=[{\"type\" : \"code_interpreter\", \"type\" : \"file_search\"}],\n",
    "  model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "\n",
    "assistant_id = \"asst_So5uPjPWR61Gy3wOf2x853ZD\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.beta.vector_stores.create(name=\"Financial Statements\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"files/novel.txt\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_x4h1WyAzInZmguPmsv5Ssg8D'])\n"
     ]
    }
   ],
   "source": [
    "message_file = client.files.create(\n",
    "  file=open(\"files/novel.txt\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Summarize the novel\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'file_from_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m file \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(file\u001b[38;5;241m=\u001b[39m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_from_path\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./files/novel.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m), purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m file\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenAI' object has no attribute 'file_from_path'"
     ]
    }
   ],
   "source": [
    "file = client.files.create(file=c   .file_from_path(\"./files/novel.txt\"), purpose=\"assistants\")\n",
    "client.files.upload(file.id, \"./files\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    ")\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run(run_id, thread_id):\n",
    "    return client.beta.threads.runs.retrieve(\n",
    "        run_id=run_id,\n",
    "        thread_id=thread_id,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_messages(thread_id):\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    for message in messages:\n",
    "        print(f\"{message.role}: {message.content[0].text.value}\")\n",
    "\n",
    "def send_message(thread_id, content):\n",
    "    return client.beta.threads.messages.create(\n",
    "        thread_id=thread_id, role=\"user\", content=content\n",
    "    )\n",
    "\n",
    "def get_tool_outputs(run_id, thread_id):\n",
    "    run = get_run(run_id, thread_id)\n",
    "    outputs = []\n",
    "    for action in run.required_action.submit_tool_outputs.tool_calls:\n",
    "        action_id = action.id\n",
    "        function = action.function\n",
    "        print(f\"Calling function : {function.name} with arg {function.arguments}\")\n",
    "        outputs.append({\n",
    "            \"output\" : functions_map[function.name](json.loads(function.arguments)),\n",
    "            \"tool_call_id\" : action_id\n",
    "        })\n",
    "    return outputs\n",
    "\n",
    "def submit_tool_outputs(run_id, thread_id):\n",
    "    outputs = get_tool_outputs(run_id, thread_id)\n",
    "    return client.beta.threads.runs.submit_tool_outputs(\n",
    "        run_id = run_id,\n",
    "        thread_id = thread_id,\n",
    "        tool_outputs = outputs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_run(run.id, thread.id).status\n",
    "#get_run(run.id, thread.id).status\n",
    "submit_tool_outputs(run.id, thread.id)\n",
    "#send_message(thread.id, \"Please go ahead!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_run(run.id, thread.id).status\n",
    "\n",
    "#get_messages(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message(thread.id, \"Now I want to know if Cloudflare is a good buy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_messages(thread.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
